# -*- coding: utf-8 -*-
"""SqueezeNets_new.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PMc_eK_4B72b4yEXtJauv9xoJj03TVMh
"""



from keras_applications.imagenet_utils import _obtain_input_shape
from keras import backend as K
from keras.layers import Input, Convolution2D, MaxPooling2D, Activation, concatenate, Dropout, warnings
from keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D
from keras.models import Model
from keras.engine.topology import get_source_inputs
from keras.utils import get_file
from keras.utils import layer_utils


sq1x1 = "squeeze1x1"
exp1x1 = "expand1x1"
exp3x3 = "expand3x3"
relu = "relu_"

WEIGHTS_PATH = "https://github.com/rcmalli/keras-squeezenet/releases/download/v1.0/squeezenet_weights_tf_dim_ordering_tf_kernels.h5"
WEIGHTS_PATH_NO_TOP = "https://github.com/rcmalli/keras-squeezenet/releases/download/v1.0/squeezenet_weights_tf_dim_ordering_tf_kernels_notop.h5"

# Modular function for Fire Node

def fire_module(x, fire_id, squeeze=16, expand=64):
    s_id = 'fire' + str(fire_id) + '/'

    if K.image_data_format() == 'channels_first':
        channel_axis = 1
    else:
        channel_axis = 3
    
    x = Convolution2D(squeeze, (1, 1), padding='valid', name=s_id + sq1x1)(x)
    x = Activation('relu', name=s_id + relu + sq1x1)(x)

    left = Convolution2D(expand, (1, 1), padding='valid', name=s_id + exp1x1)(x)
    left = Activation('relu', name=s_id + relu + exp1x1)(left)

    right = Convolution2D(expand, (3, 3), padding='same', name=s_id + exp3x3)(x)
    right = Activation('relu', name=s_id + relu + exp3x3)(right)

    x = concatenate([left, right], axis=channel_axis, name=s_id + 'concat')
    return x


# Original SqueezeNet from paper.

def SqueezeNet(include_top=True, weights='imagenet',
               input_tensor=None, input_shape=None,
               pooling=None,
               classes=1000):
    """Instantiates the SqueezeNet architecture.
    """
        
    if weights not in {'imagenet', None}:
        raise ValueError('The `weights` argument should be either '
                         '`None` (random initialization) or `imagenet` '
                         '(pre-training on ImageNet).')

    if weights == 'imagenet' and classes != 1000:
        raise ValueError('If using `weights` as imagenet with `include_top`'
                         ' as true, `classes` should be 1000')


    input_shape = _obtain_input_shape(input_shape,
                                      default_size=227,
                                      min_size=48,
                                      data_format=K.image_data_format(),
                                      require_flatten=include_top)

    if input_tensor is None:
        img_input = Input(shape=input_shape)
    else:
        if not K.is_keras_tensor(input_tensor):
            img_input = Input(tensor=input_tensor, shape=input_shape)
        else:
            img_input = input_tensor


    x = Convolution2D(64, (3, 3), strides=(2, 2), padding='valid', name='conv1')(img_input)
    x = Activation('relu', name='relu_conv1')(x)
    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool1')(x)

    x = fire_module(x, fire_id=2, squeeze=16, expand=64)
    x = fire_module(x, fire_id=3, squeeze=16, expand=64)
    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool3')(x)

    x = fire_module(x, fire_id=4, squeeze=32, expand=128)
    x = fire_module(x, fire_id=5, squeeze=32, expand=128)
    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool5')(x)

    x = fire_module(x, fire_id=6, squeeze=48, expand=192)
    x = fire_module(x, fire_id=7, squeeze=48, expand=192)
    x = fire_module(x, fire_id=8, squeeze=64, expand=256)
    x = fire_module(x, fire_id=9, squeeze=64, expand=256)
    
    if include_top:
        # It's not obvious where to cut the network... 
        # Could do the 8th or 9th layer... some work recommends cutting earlier layers.
    
        x = Dropout(0.5, name='drop9')(x)

        x = Convolution2D(classes, (1, 1), padding='valid', name='conv10')(x)
        x = Activation('relu', name='relu_conv10')(x)
        x = GlobalAveragePooling2D()(x)
        x = Activation('softmax', name='loss')(x)
    else:
        if pooling == 'avg':
            x = GlobalAveragePooling2D()(x)
        elif pooling=='max':
            x = GlobalMaxPooling2D()(x)
        elif pooling==None:
            pass
        else:
            raise ValueError("Unknown argument for 'pooling'=" + pooling)

    # Ensure that the model takes into account
    # any potential predecessors of `input_tensor`.
    if input_tensor is not None:
        inputs = get_source_inputs(input_tensor)
    else:
        inputs = img_input

    model = Model(inputs, x, name='squeezenet')

    # load weights
    if weights == 'imagenet':
        if include_top:
            weights_path = get_file('squeezenet_weights_tf_dim_ordering_tf_kernels.h5',
                                    WEIGHTS_PATH,
                                    cache_subdir='models')
        else:
            weights_path = get_file('squeezenet_weights_tf_dim_ordering_tf_kernels_notop.h5',
                                    WEIGHTS_PATH_NO_TOP,
                                    cache_subdir='models')
            
        model.load_weights(weights_path)
        if K.backend() == 'theano':
            layer_utils.convert_all_kernels_in_model(model)

        if K.image_data_format() == 'channels_first':

            if K.backend() == 'tensorflow':
                warnings.warn('You are using the TensorFlow backend, yet you '
                              'are using the Theano '
                              'image data format convention '
                              '(`image_data_format="channels_first"`). '
                              'For best performance, set '
                              '`image_data_format="channels_last"` in '
                              'your Keras config '
                              'at ~/.keras/keras.json.')
    return model

base_model = SqueezeNet(include_top=False, weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000)

import tensorflow as tf
import keras

#Uncomment when working with google colab to mount the drive

#from google.colab import drive
#drive.mount('/content/drive')
#%cd /content/drive/My\ Drive



import os
import numpy

from keras.preprocessing import image

from keras.models import Model

from keras.layers import Dense, GlobalAveragePooling2D

from keras.preprocessing.image import ImageDataGenerator

import matplotlib.pyplot as plt

# %matplotlib inline

from keras.layers import Dense

from keras.layers import Dropout

train_datagen= ImageDataGenerator()

test_datagen= ImageDataGenerator()


train_generator = train_datagen.flow_from_directory(

    directory='Dataset/Train/Labels' ,	#Give the path of the folder contaning Train data

    target_size=(224, 224),

    color_mode="rgb",

    batch_size=32,

    class_mode="categorical",

    shuffle=True,

    seed=42)


valid_datagen= ImageDataGenerator()

valid_generator = valid_datagen.flow_from_directory(

    directory='Dataset/Train/Labels',	#Give the path of the folder contaning Valid data

    target_size=(224, 224),

    color_mode="rgb",

    batch_size=32,

    class_mode="categorical",

    shuffle=True,

    seed=42)

test_generator= test_datagen.flow_from_directory(

   directory='Dataset/Train/Labels',	#Give the path of the folder contaning Test data

   target_size=(224,224),color_mode="rgb",

   class_mode="categorical",shuffle=False,seed=42)


STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size

STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size

STEP_SIZE_TEST = test_generator.n//test_generator.batch_size


base_model = SqueezeNet(include_top=False, weights='imagenet',input_tensor=None,input_shape=(224,224,3),pooling=None,classes=1000)


x = base_model.output

x = GlobalAveragePooling2D(name='avg_pool')(x)

x = Dense(256, activation='relu')(x)

x= Dropout(0.5)(x)
classes = 7
predictions = Dense(classes, activation='softmax')(x)

model = Model(inputs=base_model.input, outputs=predictions)


for layer in base_model.layers:
    layer.trainable = True

model.compile(optimizer='adam',

              loss='categorical_crossentropy',

              metrics=['accuracy'])

print(model.summary())
#give the path to save the model
cb = keras.callbacks.ModelCheckpoint("path/to/save/model", monitor='val_acc', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=1)
model.fit_generator(generator=train_generator,validation_data=valid_generator,validation_steps=STEP_SIZE_VALID,steps_per_epoch=STEP_SIZE_TRAIN,epochs=100,callbacks = [cb])



model.evaluate_generator(test_generator,steps = STEP_SIZE_TEST, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)

"This is for deployment purpose (especially for Raspberry-pi)
"""##Converting to TfLite"""

import tensorflow as tf
import numpy as np
converter  = tf.lite.TFLiteConverter.from_keras_model_file("/content/drive/My Drive/SqueezeNets/SqueezeNets_some_epochs.model", input_shapes = {'input_1' : [1,224,224,3]})

tflite_model  = converter.convert()

open("path/of/saved/model", "wb").write(tflite_model)

"""##Getting the f-1 scores"""

import os
validation_data_dir = "path/of/saved/model"
import glob
allvalidimgpaths=glob.glob(os.path.join(validation_data_dir, '*/*.jpeg'))
allvalidimgpaths+=glob.glob(os.path.join(validation_data_dir, '*/*.jpg'))
import random
random.shuffle(allvalidimgpaths)

from keras.preprocessing.image import load_img, img_to_array
validation_imgs = [img_to_array(load_img(img, target_size=(224,224))) for img in allvalidimgpaths]

validation_labels= [fn.split('/')[-2] for fn in allvalidimgpaths]

import numpy as np
np.array(validation_imgs)

print(np.shape(validation_imgs))

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
le.fit(["label_1","label_2","label_3","label_4","label_5","label_6","label_7"])
validation_labels_enc = le.transform(validation_labels)

print(validation_labels[5:9])
print(validation_labels_enc[5:9])

from keras.models import load_model
model = load_model("path/of/saved/model")

import numpy
newvalids=validation_imgs[:]

valid_imgs_array=numpy.asarray(validation_imgs)

print(valid_imgs_array.shape)
valid_imgs_array.astype('float32')

#valid_imgs_array/=255

test_predictions=model.predict(valid_imgs_array)

import numpy as np
newpreds= np.argmax(test_predictions,axis=1)

from sklearn.metrics import classification_report

print(classification_report(validation_labels_enc, newpreds, target_names=["label_1","label_2","label_3","label_4","label_5","label_6","label_7"]))


